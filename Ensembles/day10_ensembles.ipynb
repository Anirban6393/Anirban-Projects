{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been collected from 2018 FIFA World Cup Russia Official App.\n",
    "\n",
    "https://www.kaggle.com/mathan/fifa-2018-match-statistics\n",
    "\n",
    "We'll use the data that's pre-processed in the previous workshop (day 9), so that we don't repeat steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ensembles\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed data\n",
    "\n",
    "Load pre-processed data from Day 9 workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('fifa_processed_train.csv')\n",
    "df_test = pd.read_csv('fifa_processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 6) (30, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Goal Scored</th>\n",
       "      <th>On-Target</th>\n",
       "      <th>Off-Target</th>\n",
       "      <th>Corners</th>\n",
       "      <th>1st Goal</th>\n",
       "      <th>Man of the Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.476178</td>\n",
       "      <td>1.825788</td>\n",
       "      <td>2.035973</td>\n",
       "      <td>2.129917</td>\n",
       "      <td>1.441201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-1.285088</td>\n",
       "      <td>0.333417</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>-0.260364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-0.840677</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>0.920500</td>\n",
       "      <td>1.079166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.476178</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>-1.794778</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>0.427503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>1.381377</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-0.658602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>0.492555</td>\n",
       "      <td>0.333417</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>-0.405178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-1.794778</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>-0.405178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>0.333417</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>0.174078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>-0.586195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-1.285088</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>0.427503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>-0.839620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>0.333417</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>-0.224160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.492555</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>0.318892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>-1.498332</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-1.285088</td>\n",
       "      <td>-1.369139</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>0.789538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.348796</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>-1.901471</td>\n",
       "      <td>-0.586195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>1.381377</td>\n",
       "      <td>2.035973</td>\n",
       "      <td>0.920500</td>\n",
       "      <td>0.572317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>0.333417</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.476178</td>\n",
       "      <td>0.492555</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>0.753334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>-1.498332</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.094031</td>\n",
       "      <td>1.381377</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>-0.767213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-0.840677</td>\n",
       "      <td>-1.794778</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>1.622218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>0.333417</td>\n",
       "      <td>-1.498332</td>\n",
       "      <td>0.210282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>2.270199</td>\n",
       "      <td>1.610334</td>\n",
       "      <td>1.323639</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>-0.224160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>0.333417</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-1.285088</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>-0.658602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>-0.840677</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>0.391299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>2.533055</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>2.035973</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>-1.020637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>-0.840677</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>0.029264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>1.610334</td>\n",
       "      <td>0.920500</td>\n",
       "      <td>-0.332771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-0.840677</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>2.201474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-1.729499</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>-1.498332</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>2.461612</td>\n",
       "      <td>1.726778</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.476178</td>\n",
       "      <td>0.492555</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-0.187957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>-0.875823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>1.296387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-1.285088</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>0.572317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-1.729499</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>-1.901471</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.476178</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>1.726778</td>\n",
       "      <td>0.644724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>-0.092222</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>0.970555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-0.549992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>-0.396266</td>\n",
       "      <td>1.184695</td>\n",
       "      <td>0.920500</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>-0.840677</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>0.753334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>-1.095194</td>\n",
       "      <td>2.201474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>1.381377</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>0.789538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>0.492555</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>1.323639</td>\n",
       "      <td>0.680927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>-0.840677</td>\n",
       "      <td>1.184695</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>0.861945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>-1.794778</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>0.101671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-1.141675</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>-0.692055</td>\n",
       "      <td>-1.093044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>1.381377</td>\n",
       "      <td>1.184695</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>-0.912027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>0.492555</td>\n",
       "      <td>1.184695</td>\n",
       "      <td>0.920500</td>\n",
       "      <td>0.825741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.269057</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>1.184695</td>\n",
       "      <td>2.129917</td>\n",
       "      <td>1.694625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Goal Scored  On-Target  Off-Target   Corners  1st Goal  Man of the Match\n",
       "0      1.476178   1.825788    2.035973  2.129917  1.441201                 1\n",
       "1     -0.269057  -1.285088    0.333417 -1.095194 -0.260364                 1\n",
       "2     -0.269057  -0.840677   -0.092222  0.920500  1.079166                 1\n",
       "3      1.476178   0.048145   -1.794778 -0.288916  0.427503                 0\n",
       "4     -1.141675  -0.396266   -0.943500  0.114223 -1.093044                 0\n",
       "5      0.603561   1.381377   -0.092222  0.114223 -0.658602                 1\n",
       "6      0.603561   0.492555    0.333417 -1.095194 -0.405178                 0\n",
       "7      0.603561  -0.396266   -1.794778 -0.692055 -0.405178                 1\n",
       "8     -0.269057   0.048145    0.333417  0.114223  0.174078                 1\n",
       "9     -1.141675  -0.396266   -0.943500  0.114223 -1.093044                 0\n",
       "10     0.603561  -0.396266   -0.943500 -0.288916 -0.586195                 1\n",
       "11    -0.269057  -1.285088   -0.943500  0.114223  0.427503                 1\n",
       "12    -1.141675  -0.396266   -0.943500 -0.288916 -1.093044                 0\n",
       "13     0.603561   0.936966   -0.092222  0.517361 -0.839620                 1\n",
       "14    -0.269057   0.048145    0.333417 -0.692055 -0.224160                 1\n",
       "15    -0.269057   0.492555   -0.092222  0.114223  0.318892                 0\n",
       "16    -1.141675  -0.396266   -0.517861 -1.498332 -1.093044                 0\n",
       "17    -1.141675  -1.285088   -1.369139 -0.288916 -1.093044                 0\n",
       "18    -0.269057   0.048145   -0.517861 -1.095194  0.789538                 1\n",
       "19     2.348796   0.048145   -0.517861 -1.901471 -0.586195                 1\n",
       "20     0.603561   1.381377    2.035973  0.920500  0.572317                 0\n",
       "21    -1.141675  -0.396266    0.333417  0.114223 -1.093044                 0\n",
       "22     1.476178   0.492555    0.759056 -0.692055  0.753334                 1\n",
       "23    -1.141675  -0.396266   -0.943500 -1.498332 -1.093044                 0\n",
       "24     4.094031   1.381377   -0.943500 -0.692055 -0.767213                 1\n",
       "25    -0.269057  -0.840677   -1.794778 -0.692055  1.622218                 1\n",
       "26    -0.269057   0.048145    0.333417 -1.498332  0.210282                 0\n",
       "27    -1.141675   2.270199    1.610334  1.323639 -1.093044                 1\n",
       "28    -0.269057  -0.396266   -0.092222 -1.095194 -0.224160                 1\n",
       "29    -1.141675  -0.396266    0.333417  0.114223 -1.093044                 0\n",
       "..          ...        ...         ...       ...       ...               ...\n",
       "60    -0.269057  -1.285088   -0.943500 -1.095194 -0.658602                 0\n",
       "61     0.603561  -0.840677    0.759056 -0.692055  0.391299                 1\n",
       "62    -1.141675   0.048145   -0.092222  2.533055 -1.093044                 0\n",
       "63    -0.269057  -0.396266    2.035973 -0.288916 -1.020637                 0\n",
       "64     0.603561  -0.840677   -0.517861  0.517361  0.029264                 1\n",
       "65    -0.269057   0.048145    1.610334  0.920500 -0.332771                 1\n",
       "66    -0.269057  -0.840677   -0.092222 -1.095194  2.201474                 1\n",
       "67    -1.141675  -1.729499   -0.517861 -1.498332 -1.093044                 0\n",
       "68    -1.141675   0.936966    2.461612  1.726778 -1.093044                 0\n",
       "69     1.476178   0.492555   -0.092222  0.114223 -0.187957                 1\n",
       "70    -0.269057  -0.396266    0.759056 -0.692055 -0.875823                 0\n",
       "71    -0.269057   0.048145   -0.092222  0.517361  1.296387                 1\n",
       "72    -1.141675  -1.285088   -0.092222  0.114223 -1.093044                 0\n",
       "73    -0.269057   0.048145    0.759056  0.114223  0.572317                 1\n",
       "74    -1.141675  -1.729499   -0.943500 -1.095194 -1.093044                 0\n",
       "75    -1.141675  -0.396266   -0.943500 -1.901471 -1.093044                 0\n",
       "76     1.476178   0.936966    0.759056  1.726778  0.644724                 1\n",
       "77    -0.269057  -0.396266   -0.092222 -0.288916  0.970555                 1\n",
       "78     0.603561   0.048145   -0.943500  0.114223 -0.549992                 1\n",
       "79    -1.141675  -0.396266    1.184695  0.920500 -1.093044                 0\n",
       "80    -0.269057  -0.840677   -0.517861 -1.095194  0.753334                 0\n",
       "81    -0.269057   0.048145    0.759056 -1.095194  2.201474                 0\n",
       "82     0.603561   1.381377   -0.517861  0.517361  0.789538                 1\n",
       "83     0.603561   0.492555   -0.517861  1.323639  0.680927                 1\n",
       "84     0.603561  -0.840677    1.184695  0.114223  0.861945                 0\n",
       "85    -0.269057   0.936966   -1.794778 -0.692055  0.101671                 0\n",
       "86    -1.141675   0.936966    0.759056 -0.692055 -1.093044                 0\n",
       "87    -0.269057   1.381377    1.184695  0.114223 -0.912027                 1\n",
       "88     0.603561   0.492555    1.184695  0.920500  0.825741                 1\n",
       "89    -0.269057   0.936966    1.184695  2.129917  1.694625                 1\n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=626623746, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=302736279, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=809248145, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1222995504, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1731631684, splitter='best')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_estimators should be a factor of the number of samples\n",
    "# here we only have 90 training samples\n",
    "# n_jobs trains 2 in parallel (optional)\n",
    "\n",
    "# after visual inspection of a few trees\n",
    "# the trees are too specific and deep (1-3 samples at the leaf nodes)\n",
    "#\n",
    "# In practice, you can try plotting max_depth vs. accuracy in \n",
    "# a learning curve (more rigorous approach)\n",
    "rf = RandomForestClassifier(n_estimators=5, n_jobs=2, max_depth=5)\n",
    "\n",
    "# cross_validate is redundant because bagging is\n",
    "# applying a similar concept, just not repeating samples\n",
    "# more importantly, our dataset is too small, so\n",
    "# at cv=3, we have 6 validation & 12 training\n",
    "\n",
    "# 90 train / 5 trees = 18 per tree\n",
    "# at cv=3, we have 18/3 = 6 val, 12 train\n",
    "\n",
    "target = 'Man of the Match'\n",
    "Z_train = df_train.loc[:, df_train.columns != target]\n",
    "y_train = df_train[target]\n",
    "\n",
    "rf.fit(Z_train, y_train) # typically we have used cross_validate\n",
    "\n",
    "# show the trees\n",
    "rf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns accuracy\n",
    "Z_test = df_test.loc[:, df_test.columns != target]\n",
    "y_test = df_test[target]\n",
    "rf.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.67      0.77        18\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        30\n",
      "   macro avg       0.79      0.79      0.77        30\n",
      "weighted avg       0.81      0.77      0.77        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(Z_test)\n",
    "print(classification_report(y_test, y_pred)) # any improvement???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49872122, 0.14619573, 0.06443795, 0.14715951, 0.14348559])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first tree\n",
    "rf.estimators_[0].feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33979878, 0.21198542, 0.18665745, 0.0998963 , 0.16166205])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.estimators_[1].feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Goal Scored', 'On-Target', 'Off-Target', 'Corners', '1st Goal'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(tree, columns, filename):\n",
    "    from sklearn.tree import export_graphviz\n",
    "    import graphviz\n",
    "\n",
    "    export_graphviz(tree,\n",
    "                    out_file=filename,\n",
    "                    feature_names=columns,\n",
    "                    filled=True,\n",
    "                    rounded=True)\n",
    "    source = graphviz.Source.from_file(filename)\n",
    "    source.render(view=True)\n",
    "\n",
    "plot_tree(rf.estimators_[0], Z_train.columns, 'fifa_tree1_depth5.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(rf.estimators_[1], Z_train.columns, 'fifa_tree2_depth5.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Goal Scored', 'On-Target', 'Off-Target', 'Corners', '1st Goal',\n",
       "       'Man of the Match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limit max_depth to avoid poor performance in boosting\n",
    "# due to overfitting in the first generation tree\n",
    "#\n",
    "# max_depth determined by visual inspection of first gen tree\n",
    "# can tune max_depth by plotting accuracy vs. depth\n",
    "model = DecisionTreeClassifier(max_depth=7)\n",
    "\n",
    "ada = AdaBoostClassifier(model, n_estimators=50)\n",
    "ada.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many models were generated\n",
    "len(ada.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'estimator error'), Text(0.5, 0, 'n_estimators')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# errors for each successive generation (lower = better)\n",
    "# looks like n_estimators=3 is good enough\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ada.estimator_errors_, marker='o')\n",
    "ax.set(xlabel='n_estimators', ylabel='estimator error')\n",
    "\n",
    "# but, what is this error on? Training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for each successive generation (higher = better)\n",
    "ada.estimator_weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(ada.estimators_[0], Z_train.columns, 'fifa_boost_tree1.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(ada.estimators_[1], Z_train.columns, 'fifa_boost_tree2.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09518392, 0.20206831, 0.16306453, 0.16873171, 0.37095153])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        18\n",
      "           1       0.60      0.75      0.67        12\n",
      "\n",
      "   micro avg       0.70      0.70      0.70        30\n",
      "   macro avg       0.70      0.71      0.70        30\n",
      "weighted avg       0.72      0.70      0.70        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "y_pred_ada = ada.predict(Z_test)\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
